{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install selenium\n",
    "# !apt-get update\n",
    "# !apt install chromium-chromedriver\n",
    "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "\n",
    "import sys\n",
    "# sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f0A-e0hvvPS",
    "outputId": "f615e252-19bf-4841-e95e-e6421ed4cb8c"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\jws48\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from selenium) (1.26.12)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (19.3.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.2.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\" in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.0)\n",
      "Requirement already satisfied: idna in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6; extra == \"socks\" in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\"->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jws48\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n"
   ],
   "metadata": {
    "id": "ZRvgb5pzEDSC"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실종동물 스크래핑"
   ],
   "metadata": {
    "id": "1qpV72AkVuaq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [긴급] 실종 동물 스크래핑"
   ],
   "metadata": {
    "id": "OkliPHsbWrvv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def emergency_scraping(animal_url, wd):\n",
    "  try:\n",
    "    emergency_animals = []\n",
    "\n",
    "    for t in range(1, 100):\n",
    "      for i in range(1, 4):\n",
    "        emergency_url = wd.find_element(By.XPATH, '/html/body/div[4]/div/div/div/div[%d]/div[1]/div[%d]/div/a' %(t,i) ).get_attribute('href')\n",
    "        emergency_animals.append(emergency_url)\n",
    "\n",
    "        \n",
    "  except:\n",
    "    pass\n",
    "  return emergency_animals\n"
   ],
   "metadata": {
    "id": "zgcnkgfvWqsT"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [실종] 실종 동물 스크래핑"
   ],
   "metadata": {
    "id": "DbtiG0-j-2B7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def missing_animals_url(animal, wd):\n",
    "  try: \n",
    "    missing_animals= []\n",
    "    totalpages = wd.find_element(By.XPATH, '/html/body/div[6]/div/div/div/p').text\n",
    "    page = totalpages.split(\" \")\n",
    "    last = int(page[6]) + 1\n",
    "    \n",
    "    for p in range(1, last):\n",
    "      url = 'http://www.angel.or.kr/index.php?code=%s&page=%d' %(animal, p)\n",
    "      wd.get(url)\n",
    "      for t in range(1, 6):\n",
    "        for i in range(1, 5):\n",
    "          if(p==1):\n",
    "            missing = wd.find_element(By.XPATH, '/html/body/div[5]/div/div/div/div[%d]/div[1]/div[%d]/h3' %(t,i) ).text\n",
    "          else:\n",
    "            missing = wd.find_element(By.XPATH, '/html/body/div[4]/div/div/div/div[%d]/div[1]/div[%d]/h3' %(t,i) ).text\n",
    "\n",
    "          if(\"실종\" in missing):  \n",
    "            if(p==1):\n",
    "              missing_url = wd.find_element(By.XPATH, '//html/body/div[5]/div/div/div/div[%d]/div[1]/div[%d]/div/a' %(t,i) ).get_attribute('href')\n",
    "            else:\n",
    "              missing_url = wd.find_element(By.XPATH, '//html/body/div[4]/div/div/div/div[%d]/div[1]/div[%d]/div/a' %(t,i) ).get_attribute('href')\n",
    "            missing_animals.append(missing_url)\n",
    "  except: \n",
    "    pass\n",
    "\n",
    "\n",
    "  return missing_animals"
   ],
   "metadata": {
    "id": "jDJTaL07-7Ud"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 실종 동물 상세 정보"
   ],
   "metadata": {
    "id": "qdNm9_UBtO1K"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def animals_info_scraping(animal_info_url, wd):\n",
    "\n",
    "  idArr = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div/div[2]/p').text.split(\"\\n\")[0].split(\"|\")[2].split()\n",
    "  if(len(idArr[1].split(',')) == 2) :\n",
    "    id = int(idArr[1].split(',')[0] + idArr[1].split(',')[1])\n",
    "  else :\n",
    "    id = int(idArr[1])\n",
    "  animal = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div/table/tbody/tr[1]/td[2]').text\n",
    "  info = animal.split('/')\n",
    "  find = info[len(info)-4]\n",
    "  gender = info[len(info)-3]\n",
    "  age = info[len(info)-2]\n",
    "  name = info[len(info)-1]\n",
    "  missingDay = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div/table/tbody/tr[2]/td[2]').text\n",
    "  try:\n",
    "    datetime_format = \"%Y-%m-%d\"\n",
    "    missingDay = datetime.strptime(missingDay, datetime_format).date()\n",
    "  except:\n",
    "    return\n",
    "\n",
    "  location = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div/table/tbody/tr[3]/td[2]').text\n",
    "  description = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div/table/tbody/tr[5]/td[2]').text\n",
    "  description = description.replace(\"\\n\", \" \")\n",
    "  description = description.replace(\"\\t\", \" \")\n",
    "\n",
    "  # 이미지 클릭해 이미지로 이동\n",
    "  try:\n",
    "    img_url = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div/div[3]/div[1]/div[1]/div/a').get_attribute('href')\n",
    "    wd.get(img_url)\n",
    "    img = wd.find_element(By.XPATH, '/html/body/img').get_attribute('src')\n",
    "  except:\n",
    "    img = ''\n",
    "    pass\n",
    "\n",
    "\n",
    "  return [id, find, gender, age, name, missingDay, location ,description, img]"
   ],
   "metadata": {
    "id": "h2i6O5UetOZP"
   },
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## URL_스크래핑 : 강아지"
   ],
   "metadata": {
    "id": "5Zqz5ttGV2q9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def dog_url_scraping():\n",
    "\n",
    "  wd = webdriver.Chrome('chromedriver', options= chrome_options)\n",
    "  wd.implicitly_wait(3)\n",
    "  \n",
    "  dogs_url = 'http://www.angel.or.kr/index.php?code=dog'\n",
    "  wd.get(dogs_url)\n",
    "  \n",
    "  dogs_df = pd.DataFrame(columns=(\"ID\", \"Find\", \"Gender\", \"Age\", \"Name\", \"MissingDay\", \"Location\", \"Description\", \"IMG\"))\n",
    "\n",
    "  emergency_dogs = emergency_scraping(dogs_url, wd)\n",
    "  \n",
    "  dogs_idx = 0\n",
    "  for dog_url in emergency_dogs:\n",
    "    wd.get(dog_url)\n",
    "    dogs_df.loc[dogs_idx] = animals_info_scraping(dog_url, wd)\n",
    "    dogs_idx += 1\n",
    "\n",
    "  wd.get(dogs_url)\n",
    "  missing_dogs_url = missing_animals_url('dog', wd)\n",
    "  \n",
    "  for dog_url in missing_dogs_url:\n",
    "    wd.get(dog_url)\n",
    "    dogs_df.loc[dogs_idx] = animals_info_scraping(dog_url, wd)\n",
    "    dogs_idx += 1\n",
    "\n",
    "  return dogs_df\n",
    "  \n"
   ],
   "metadata": {
    "id": "1qwr1t0UVyFY"
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## URL_스크래핑 : 고양이"
   ],
   "metadata": {
    "id": "sbG-dPLkWUMJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def cat_url_scraping():\n",
    "  wd = webdriver.Chrome('chromedriver', options= chrome_options)\n",
    "  wd.implicitly_wait(3)\n",
    "  cats_url = 'http://www.angel.or.kr/index.php?code=cat'\n",
    "\n",
    "  wd.get(cats_url)\n",
    "\n",
    "  cats_df = pd.DataFrame(columns=(\"ID\", \"Find\", \"Gender\", \"Age\", \"Name\", \"MissingDay\", \"Location\", \"Description\", \"IMG\"))\n",
    "\n",
    "  emergency_cats = emergency_scraping(cats_url, wd)\n",
    "\n",
    "  cats_idx = 0\n",
    "  for cat_url in emergency_cats:\n",
    "    wd.get(cat_url)\n",
    "    cats_df.loc[cats_idx] = animals_info_scraping(cat_url, wd)\n",
    "    cats_idx += 1\n",
    "\n",
    "  wd.get(cats_url)\n",
    "  missing_cats_url = missing_animals_url('cat', wd)\n",
    "\n",
    "  for cat_url in missing_cats_url:\n",
    "    wd.get(cat_url)\n",
    "    cats_df.loc[cats_idx] = animals_info_scraping(cat_url, wd)\n",
    "    cats_idx += 1\n",
    "\n",
    "  return cats_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## URL_스크래핑 : 그외 동물"
   ],
   "metadata": {
    "id": "K2wBxpLRWUXD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def other_url_scraping():\n",
    "  wd = webdriver.Chrome('chromedriver', options= chrome_options)\n",
    "  wd.implicitly_wait(3)\n",
    "  others_url = 'http://www.angel.or.kr/index.php?code=other'\n",
    "\n",
    "  wd.get(others_url)\n",
    "\n",
    "  emergency_others = emergency_scraping(others_url, wd)\n",
    "\n",
    "  others_df = pd.DataFrame(columns=(\"ID\", \"Find\", \"Gender\", \"Age\", \"Name\", \"MissingDay\", \"Location\", \"Description\", \"IMG\"))\n",
    "\n",
    "  others_idx = 0\n",
    "  for other_url in emergency_others:\n",
    "    wd.get(other_url)\n",
    "    others_df.loc[others_idx] = animals_info_scraping(other_url, wd)\n",
    "    others_idx += 1\n",
    "\n",
    "  wd.get(others_url)\n",
    "  missing_others_url = missing_animals_url('other', wd)\n",
    "\n",
    "  for other_url in missing_others_url:\n",
    "    wd.get(other_url)\n",
    "    others_df.loc[others_idx] = animals_info_scraping(other_url, wd)\n",
    "    others_idx += 1\n",
    "  return others_df\n"
   ],
   "metadata": {
    "id": "5kowZHyNWUXD"
   },
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dogs_df = dog_url_scraping()\n",
    "cats_df = cat_url_scraping()\n",
    "others_df = other_url_scraping()"
   ],
   "metadata": {
    "id": "hd3E0a5X7BBs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dogs_df_clone = dogs_df\n",
    "cats_df_clone = cats_df\n",
    "others_df_clone = others_df\n",
    "\n",
    "merge_df = pd.concat([dogs_df_clone, cats_df_clone])\n"
   ],
   "metadata": {
    "id": "mnI0049WsjPm"
   },
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "merge_df = pd.concat([merge_df, others_df_clone])\n",
    "merge_df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EY1xhcbVtGki",
    "outputId": "6db30738-9f43-447f-c7f1-31db93418059"
   },
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "              Find  Gender    Age        Name  MissingDay  \\\n0     기타견종(케인코르소)      암컷     3살      이름(일순이)  2022-09-18   \n1        저먼 세퍼드 독      수컷     8살        이름(칸)  2022-09-17   \n2    믹스견(믹스견(건정))      암컷    14살       이름(미키)  2022-09-16   \n3           포메라니언      암컷     6살       이름(이브)  2022-09-13   \n4     이탈리언 그레이하운드      암컷     6살       이름(세모)  2022-09-01   \n..             ...     ...    ...         ...         ...   \n336           앵무새      수컷     1살       이름(시월)  2016-08-31   \n337           앵무새    성별모름     2살       이름(바로)  2016-08-28   \n338           앵무새      암컷     4살    이름(왕관앵무새)  2016-08-24   \n339           앵무새      암컷     4살       이름(루비)  2016-08-16   \n340     포유류(프레리독)      수컷     3살       이름(구찌)  2016-08-14   \n\n                            Location  \\\n0       경상남도 진주시 동방호텔 건너편 선학산 등산로 인근   \n1              경기도 화성시 장안면 사곡2리마을회관앞   \n2           부산광역시 연제구 연산6동 쌍미천로 73번길   \n3             전라북도 김제시 용지면 용지면사무소 근처   \n4        충청남도 아산시 아산 은행나무길 / 삽교회전교차로   \n..                               ...   \n336              대전광역시 동구 자양동 196-11   \n337             경기도 안양시 동안구 대륭테크노 근처   \n338         경기도 고양시 덕양구 행신동 서정마을 1단지   \n339  경기도 수원시 장안구 정자1동 동신아파트 104동1단지앞   \n340   서울특별시 강서구 등촌2동 sk동방주유소 뒷편 주택골목   \n\n                                           Description  \\\n0    오른쪽눈 체리아이 있구요 검정몸색에 가슴과 발가락만 흰털이에요 겁이 너무 많아요 찾...   \n1    40키로전후 사람을 잘따르고 순한편, 갈색털베이스에 등쪽 검은털 분포 뒷다리 힘이 ...   \n2    검정색 믹스견입니다. 최근 피부병으로 몸털을 밀어서 얼굴과 꼬리끝부분만 털이 길고 ...   \n3    전체적으로 황색인데 가슴,배쪽은 흰털 사람 엄청 좋아함 눈 주위가 하얗고 아이라인이...   \n4                얼룩무늬 그레이하운드과 휘펫 노락색옷입고있습니다 사슴같이 말랐습니다   \n..                                                 ...   \n336  왕관앵무 루티노 이며, 윙트리밍(윙컷)이 전혀 되지 않은 아이입니다. 발견시 잡으려...   \n337                                         초록색 앵무새입니다   \n338                   왕관앵무 회색새입니다 사람 잘따르고 다리가 힘이조금 약해요   \n339   왕관앵무새이며노란색이고볼에는연지곤지처럼생겼습니다.낯을많이가려서잡으려하면날라갈수도있습니다   \n340  앞발톱 하나, 뒷발톱 두개 없음 앞왼쪽발목 상처있음 중성화완료 *이메일확인을 못하니...   \n\n                                                   IMG  \n0    http://www.angel.or.kr/report/dog/upImg/166364...  \n1    http://www.angel.or.kr/report/dog/upImg/166360...  \n2    http://www.angel.or.kr/report/dog/upImg/166350...  \n3    http://www.angel.or.kr/report/dog/upImg/166313...  \n4    http://www.angel.or.kr/report/dog/upImg/166313...  \n..                                                 ...  \n336  http://www.angel.or.kr/report/other/upImg/1472...  \n337  http://www.angel.or.kr/report/other/upImg/1472...  \n338  http://www.angel.or.kr/report/other/upImg/1472...  \n339  http://www.angel.or.kr/report/other/upImg/1471...  \n340  http://www.angel.or.kr/report/other/upImg/1471...  \n\n[8088 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Find</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Name</th>\n      <th>MissingDay</th>\n      <th>Location</th>\n      <th>Description</th>\n      <th>IMG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>기타견종(케인코르소)</td>\n      <td>암컷</td>\n      <td>3살</td>\n      <td>이름(일순이)</td>\n      <td>2022-09-18</td>\n      <td>경상남도 진주시 동방호텔 건너편 선학산 등산로 인근</td>\n      <td>오른쪽눈 체리아이 있구요 검정몸색에 가슴과 발가락만 흰털이에요 겁이 너무 많아요 찾...</td>\n      <td>http://www.angel.or.kr/report/dog/upImg/166364...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>저먼 세퍼드 독</td>\n      <td>수컷</td>\n      <td>8살</td>\n      <td>이름(칸)</td>\n      <td>2022-09-17</td>\n      <td>경기도 화성시 장안면 사곡2리마을회관앞</td>\n      <td>40키로전후 사람을 잘따르고 순한편, 갈색털베이스에 등쪽 검은털 분포 뒷다리 힘이 ...</td>\n      <td>http://www.angel.or.kr/report/dog/upImg/166360...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>믹스견(믹스견(건정))</td>\n      <td>암컷</td>\n      <td>14살</td>\n      <td>이름(미키)</td>\n      <td>2022-09-16</td>\n      <td>부산광역시 연제구 연산6동 쌍미천로 73번길</td>\n      <td>검정색 믹스견입니다. 최근 피부병으로 몸털을 밀어서 얼굴과 꼬리끝부분만 털이 길고 ...</td>\n      <td>http://www.angel.or.kr/report/dog/upImg/166350...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>포메라니언</td>\n      <td>암컷</td>\n      <td>6살</td>\n      <td>이름(이브)</td>\n      <td>2022-09-13</td>\n      <td>전라북도 김제시 용지면 용지면사무소 근처</td>\n      <td>전체적으로 황색인데 가슴,배쪽은 흰털 사람 엄청 좋아함 눈 주위가 하얗고 아이라인이...</td>\n      <td>http://www.angel.or.kr/report/dog/upImg/166313...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>이탈리언 그레이하운드</td>\n      <td>암컷</td>\n      <td>6살</td>\n      <td>이름(세모)</td>\n      <td>2022-09-01</td>\n      <td>충청남도 아산시 아산 은행나무길 / 삽교회전교차로</td>\n      <td>얼룩무늬 그레이하운드과 휘펫 노락색옷입고있습니다 사슴같이 말랐습니다</td>\n      <td>http://www.angel.or.kr/report/dog/upImg/166313...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>336</th>\n      <td>앵무새</td>\n      <td>수컷</td>\n      <td>1살</td>\n      <td>이름(시월)</td>\n      <td>2016-08-31</td>\n      <td>대전광역시 동구 자양동 196-11</td>\n      <td>왕관앵무 루티노 이며, 윙트리밍(윙컷)이 전혀 되지 않은 아이입니다. 발견시 잡으려...</td>\n      <td>http://www.angel.or.kr/report/other/upImg/1472...</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>앵무새</td>\n      <td>성별모름</td>\n      <td>2살</td>\n      <td>이름(바로)</td>\n      <td>2016-08-28</td>\n      <td>경기도 안양시 동안구 대륭테크노 근처</td>\n      <td>초록색 앵무새입니다</td>\n      <td>http://www.angel.or.kr/report/other/upImg/1472...</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>앵무새</td>\n      <td>암컷</td>\n      <td>4살</td>\n      <td>이름(왕관앵무새)</td>\n      <td>2016-08-24</td>\n      <td>경기도 고양시 덕양구 행신동 서정마을 1단지</td>\n      <td>왕관앵무 회색새입니다 사람 잘따르고 다리가 힘이조금 약해요</td>\n      <td>http://www.angel.or.kr/report/other/upImg/1472...</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>앵무새</td>\n      <td>암컷</td>\n      <td>4살</td>\n      <td>이름(루비)</td>\n      <td>2016-08-16</td>\n      <td>경기도 수원시 장안구 정자1동 동신아파트 104동1단지앞</td>\n      <td>왕관앵무새이며노란색이고볼에는연지곤지처럼생겼습니다.낯을많이가려서잡으려하면날라갈수도있습니다</td>\n      <td>http://www.angel.or.kr/report/other/upImg/1471...</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>포유류(프레리독)</td>\n      <td>수컷</td>\n      <td>3살</td>\n      <td>이름(구찌)</td>\n      <td>2016-08-14</td>\n      <td>서울특별시 강서구 등촌2동 sk동방주유소 뒷편 주택골목</td>\n      <td>앞발톱 하나, 뒷발톱 두개 없음 앞왼쪽발목 상처있음 중성화완료 *이메일확인을 못하니...</td>\n      <td>http://www.angel.or.kr/report/other/upImg/1471...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8088 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DB에 데이터 삽입"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\jws48\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\jws48\\anaconda3\\lib\\site-packages (1.3.18)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql\n",
    "!pip install sqlalchemy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "# pymysql.install_as_MySQLdb()\n",
    "# import MySQLdb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "db_connection = create_engine(\"mysql+pymysql://ssafy:ssafy@localhost:3306/lo-fi\")\n",
    "conn = db_connection.connect()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# animal_df = pd.read_csv('./missing_animal.csv')\n",
    "# animal_df = animal_df.drop(['Unnamed: 0'], axis=1)\n",
    "# animal_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-68-8a84de4bae31>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m }\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mmerge_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_sql\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'missing_animal'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcon\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mif_exists\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'replace'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtypesql\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'merge_df' is not defined"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "dtypesql = {\n",
    "  'Find': sqlalchemy.types.VARCHAR(64),\n",
    "  'Gender': sqlalchemy.types.VARCHAR(64),\n",
    "  'Age': sqlalchemy.types.VARCHAR(16),\n",
    "  'Name':sqlalchemy.types.VARCHAR(64),\n",
    "  'MissingDay' : sqlalchemy.types.DATETIME,\n",
    "  'Location' :sqlalchemy.types.VARCHAR(64),\n",
    "}\n",
    "\n",
    "merge_df.to_sql(name='missing_animal', con = conn, if_exists='replace', index=True, dtype=dtypesql)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'Find', 'Gender', 'Age', 'Name', 'MissingDay', 'Location',\n",
      "       'Description', 'IMG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_sql_table('missing_animal', conn)\n",
    "print(data.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
